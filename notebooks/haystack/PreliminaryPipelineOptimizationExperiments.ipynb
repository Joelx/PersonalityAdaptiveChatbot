{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7106afa-fc64-400a-b731-241255bd4010",
   "metadata": {},
   "source": [
    "# TF-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16dfd869-a099-4c1b-821d-a70d422540c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Learn the vocabulary and IDF values\n",
    "tfidf = vectorizer.fit(corpus)\n",
    "# Transform the data into a TF-IDF representation\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0bf1989-be1c-4528-a337-a176f55a5cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.4694172843223779\n",
      "  (0, 2)\t0.6172273175654565\n",
      "  (0, 6)\t0.3645443967613799\n",
      "  (0, 3)\t0.3645443967613799\n",
      "  (0, 8)\t0.3645443967613799\n",
      "  (1, 5)\t0.47890874975914965\n",
      "  (1, 1)\t0.7284448965638161\n",
      "  (1, 6)\t0.2828512224204681\n",
      "  (1, 3)\t0.2828512224204681\n",
      "  (1, 8)\t0.2828512224204681\n",
      "  (2, 4)\t0.49711994139048143\n",
      "  (2, 7)\t0.49711994139048143\n",
      "  (2, 0)\t0.49711994139048143\n",
      "  (2, 6)\t0.2936070455647438\n",
      "  (2, 3)\t0.2936070455647438\n",
      "  (2, 8)\t0.2936070455647438\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956958a3-055e-4a72-9e68-6d1dff83c83f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m vectorizer\u001b[38;5;241m.\u001b[39mfit(text)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# get the idf values as a dictionary\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m idf_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m(), vectorizer\u001b[38;5;241m.\u001b[39midf_))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(idf_dict)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# example input data\n",
    "text = [\"This is the first document.\", \"This is the second document.\", \"And this is the third one.\"]\n",
    "\n",
    "# fit TfidfVectorizer on the input data\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# get the idf values as a dictionary\n",
    "idf_dict = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "\n",
    "print(idf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94463ce-c3c8-4435-9236-36298a30c1ef",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b136c661-70e5-4ce8-a149-1e8c49b0d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 20 30]]\n",
      "Scaled data:\n",
      " [[0.         0.         0.        ]\n",
      " [0.33333333 0.16666667 0.11111111]\n",
      " [0.66666667 0.33333333 0.22222222]\n",
      " [1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "X = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9],\n",
    "             [10, 20, 30]])\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the dataset and transform the data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Print the original and scaled data\n",
    "print(\"Original data:\\n\", X)\n",
    "print(\"Scaled data:\\n\", X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "575ef6da-d402-4f66-96ca-2da55b1e1a62",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3497165141.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    arr = np.array([ 1.08933069e-01 -2.84139284e-03 -5.27260316e-02  4.13724785e-01\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([ 1.08933069e-01 -2.84139284e-03 -5.27260316e-02  4.13724785e-01\n",
    "   1.44465396e-01  1.38774996e-01  3.51667295e-01  6.54273964e-02\n",
    "  -5.52708724e-02 -1.81993941e-01  4.22297880e-01  5.15880563e-02\n",
    "  -3.05113273e-01  1.43349794e-01 -1.21152228e-01 -2.31597222e-01\n",
    "  -3.07357543e-01  8.86052096e-02  4.03190722e-01 -7.37392502e-02\n",
    "   2.07202403e-02 -1.12386612e-01 -2.57839782e-01 -6.27773106e-02\n",
    "  -8.19788826e-02  1.22168045e-02  6.84443290e-02  1.46764473e-02\n",
    "  -9.20043780e-02 -2.78895573e-01  4.08588581e-01  2.02044258e-01\n",
    "   3.60652947e-01  4.43511064e-01 -1.89840198e-01 -1.09522139e-01\n",
    "   3.20724274e-02 -4.31187695e-01  1.53092130e-01 -2.55831789e-01\n",
    "  -3.26892584e-01  8.71650477e-02  2.41542970e-01  7.74605324e-03\n",
    "  -5.07378702e-02 -2.35535227e-01 -2.07130574e-01  4.07378707e-01\n",
    "   6.13721137e-02  1.40562137e-01 -9.87373653e-02 -5.71632981e-02\n",
    "  -3.67666805e-01 -1.20163512e-01 -2.53284062e-01 -7.71040606e-02\n",
    "  -9.01437296e-02 -1.33207548e-01  2.46512294e-02  8.34610891e-02\n",
    "   2.43734613e-01 -1.96953384e-01  1.22644007e-04 -1.06559116e-01\n",
    "   2.41587202e-01  1.02710898e-01 -9.92247527e-02  4.84431808e-02\n",
    "   1.08371076e-01  3.72994889e-01 -3.56305325e-01 -9.28994560e-02\n",
    "  -1.97235460e-01  2.24776106e-01 -1.88192427e-02  1.16094920e-01\n",
    "  -1.87618074e-01 -2.82530356e-02  6.03805122e-02  7.88773308e-02\n",
    "  -3.89452161e-02 -1.41096822e-01 -2.38101701e-01  1.45941513e-02\n",
    "   1.17615896e-01 -9.90703404e-02  1.10595179e-01 -2.47810872e-01\n",
    "  -1.44065778e-01 -2.69514440e-02 -2.68810689e-01 -2.32335232e-01\n",
    "   2.77959131e-01  4.25542643e-02  2.21056166e-01 -6.89564341e-02\n",
    "   5.99241927e-02 -3.45669103e-02 -1.11935913e-01  1.92940266e-01])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5868f-8602-44b5-aafc-ea4c2e216623",
   "metadata": {},
   "source": [
    "# PyMagnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bc4f80-18dd-4e59-a65d-df619dc785d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymagnitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymagnitude\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../models/embeddings/wiki.de.vec.magnitude\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m vectors \u001b[38;5;241m=\u001b[39m pymagnitude\u001b[38;5;241m.\u001b[39mMagnitude(model_path)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymagnitude'"
     ]
    }
   ],
   "source": [
    "import pymagnitude\n",
    "\n",
    "model_path='../../models/embeddings/wiki.de.vec.magnitude'\n",
    "vectors = pymagnitude.Magnitude(model_path)\n",
    "\n",
    "# Get the vector representation of the query \"hello world\"\n",
    "query_vec = vectors.query(\"hello world\")\n",
    "\n",
    "print(query_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb2666-cdff-4f37-8ae6-d55361a8ea64",
   "metadata": {},
   "source": [
    "# Sentiment Transformers Oliverguhr german Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f53ccb-bffc-4a59-a59b-9b75fa8af5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "class SentimentModel():\n",
    "    def __init__(self, model_name: str = \"oliverguhr/german-sentiment-bert\"):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.clean_chars = re.compile(r'[^A-Za-züöäÖÜÄß ]', re.MULTILINE)\n",
    "        self.clean_http_urls = re.compile(r'https*\\S+', re.MULTILINE)\n",
    "        self.clean_at_mentions = re.compile(r'@\\S+', re.MULTILINE)\n",
    "\n",
    "    def predict_sentiment(self, texts: List[str]) -> List[str]:\n",
    "        texts = [self.clean_text(text) for text in texts]\n",
    "        # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        # truncation=True limits number of tokens to model's limitations (512)\n",
    "        encoded = self.tokenizer.batch_encode_plus(texts, padding=True, add_special_tokens=True, truncation=True,\n",
    "                                                   return_tensors=\"pt\")\n",
    "        encoded = encoded.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**encoded)\n",
    "\n",
    "        # Array structure: [pos, neg, neu]\n",
    "        probs = torch.nn.functional.softmax(logits[0], dim=-1).tolist()  # EDITED TO GET PROBABILITIES\n",
    "        label_ids = torch.argmax(logits[0], axis=1)\n",
    "        return ([self.model.config.id2label[label_id.item()] for label_id in label_ids], probs)\n",
    "\n",
    "    def replace_numbers(self, text: str) -> str:\n",
    "        return text.replace(\"0\", \" null\").replace(\"1\", \" eins\").replace(\"2\", \" zwei\") \\\n",
    "            .replace(\"3\", \" drei\").replace(\"4\", \" vier\").replace(\"5\", \" fünf\") \\\n",
    "            .replace(\"6\", \" sechs\").replace(\"7\", \" sieben\").replace(\"8\", \" acht\") \\\n",
    "            .replace(\"9\", \" neun\")\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = self.clean_http_urls.sub('', text)\n",
    "        text = self.clean_at_mentions.sub('', text)\n",
    "        text = self.replace_numbers(text)\n",
    "        text = self.clean_chars.sub('', text)  # use only text chars                          \n",
    "        text = ' '.join(text.split())  # substitute multiple whitespace with single whitespace   \n",
    "        text = text.strip().lower()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a45171-9235-42ae-ac10-cf81777f3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sentiment_scores(text):\n",
    "    sid = SentimentModel()\n",
    "    neg = []\n",
    "    neu = []\n",
    "    pos = []\n",
    "\n",
    "\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    neg_temp = []\n",
    "    pos_temp = []\n",
    "    neu_temp = []\n",
    "    for sentence in sentences:\n",
    "        # If the sentence is smaller than 4 words (punctuation included)\n",
    "        # sentiment results are all over the place\n",
    "        if len(word_tokenize(sentence)) < 4:\n",
    "            continue\n",
    "        # print(sentence)\n",
    "        sentiments, probs = sid.predict_sentiment([sentence])\n",
    "        # print(probs)\n",
    "        pos_temp.append(round(probs[0][0], 3))\n",
    "        neg_temp.append(round(probs[0][1], 3))\n",
    "        neu_temp.append(round(probs[0][2], 3))\n",
    "    # print(pos)\n",
    "    pos.append(np.mean(pos_temp))\n",
    "    # print(pos)\n",
    "    neg.append(np.mean(neg_temp))\n",
    "    neu.append(np.mean(neu_temp))\n",
    "    print(neg)\n",
    "\n",
    "    neg = np.array(neg).reshape(-1, 1)\n",
    "    print(neg)\n",
    "    neu = np.array(neu).reshape(-1, 1)\n",
    "    pos = np.array(pos).reshape(-1, 1)\n",
    "\n",
    "    return np.concatenate([neg, pos, neu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17cf9a38-6180-48f6-996e-02400ba6b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.929]\n",
      "[[0.929]]\n",
      "[[0.929 0.07  0.001]]\n"
     ]
    }
   ],
   "source": [
    "sentiment = calc_sentiment_scores(\"hallo! wie gehts dir? super tag heute\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42e9772e-e053-4034-9101-a3a5c7d4e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.929]\n",
      " [0.07 ]\n",
      " [0.001]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(sentiment).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8619c-9843-4077-821f-36178f736f85",
   "metadata": {},
   "source": [
    "# Sentiment Transformers Model XLM roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7941ad4-c130-43eb-b7cb-ad22bfd034a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.8387\n",
      "2) neutral 0.1454\n",
      "3) negative 0.0159\n",
      "[2 1 0]\n",
      "[0.01590338 0.14535907 0.8387375 ]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "text = \"hallo! wie gehts dir? super tag heute\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "\n",
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    \n",
    "print(ranking)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3fedda-e617-4ff4-bbc0-fbb8bef8d99f",
   "metadata": {},
   "source": [
    "# Punctuation count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65bca28d-d81f-4e1f-8a9c-fcdaf315e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def count_punctuations(text):\n",
    "    puncts = []\n",
    "    punctuations = set(string.punctuation)\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    puncts.append(count(text,punctuations))\n",
    "    \n",
    "    return np.array(puncts).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e88edb16-7316-47a9-9c45-ee70e72c885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]]\n"
     ]
    }
   ],
   "source": [
    "print(count_punctuations(\"hallo! wie gehts dir? super tag heute.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d727f82-ad27-4f51-9954-965655901b7c",
   "metadata": {},
   "source": [
    "# Text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3f7111d-b2b9-49a3-b2cf-ba83f13ac0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(text):\n",
    "    longest_word_length = []\n",
    "    mean_word_length = []\n",
    "    length_in_chars = []\n",
    "\n",
    "    length_in_chars.append(len(text))\n",
    "    longest_word_length.append(len(max(text.split(), key=len)))\n",
    "    mean_word_length.append(np.mean([len(word) for word in text.split()]))\n",
    "\n",
    "    longest_word_length = np.array(longest_word_length).reshape(-1, 1)\n",
    "    mean_word_length = np.array(mean_word_length).reshape(-1, 1)\n",
    "    length_in_chars = np.array(length_in_chars).reshape(-1, 1)\n",
    "\n",
    "    return np.concatenate([longest_word_length, mean_word_length, length_in_chars], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a884eceb-3e74-4db3-8c95-27670f8b9dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.          4.57142857 38.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(text_features(\"hallo! wie gehts dir? super tag heute.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94b0ab-0c59-49a8-a315-7206c8bdfc35",
   "metadata": {},
   "source": [
    "# New fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1268cbb4-16c2-46c6-beb8-7a9138a66bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "\n",
    "def fasttext_embeddings(df, idf_dict, model) -> List[float]:\n",
    "    vectors = []\n",
    "    for text in tqdm_notebook(df.text.values):\n",
    "        w2v_vectors = []\n",
    "        weights = []\n",
    "        for word in word_tokenize(text):\n",
    "            try:\n",
    "                # If the word is in the vocabulary, return its embedding\n",
    "                vector = model[word]\n",
    "            except KeyError:\n",
    "                # If the word is not in the vocabulary, get the embedding of its subwords\n",
    "                subwords = model.get_subwords(word)\n",
    "                if len(subwords) > 0:\n",
    "                    subword_embeddings = [model.get_word_vector(subword) for subword in subwords]\n",
    "                    vector = np.mean(subword_embeddings, axis=0)\n",
    "                else:\n",
    "                    # If the word and its subwords are not in the vocabulary, return None\n",
    "                    vector = None\n",
    "            w2v_vectors.append(vector)\n",
    "            weights.append(idf_dict.get(word, 1))\n",
    "        vectors.append(np.average(w2v_vectors, axis = 0, weights = weights))\n",
    "    print(np.array(vectors).size)\n",
    "    print(np.array(vectors).shape)\n",
    "    return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "235b3228-9b2c-4967-ba3b-3e12f85086bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'text': [\"hallo test text 1\", \"test text2\", \"noch ein text nummer 3\"]}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7df0ee42-a199-482e-a721-4a5a446aa77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hallo test text 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test text2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noch ein text nummer 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text\n",
       "0       hallo test text 1\n",
       "1              test text2\n",
       "2  noch ein text nummer 3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60b5b8d6-85bb-4cc3-a72e-72fdecb39002",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict = {'auch': 1.0, 'dies': 1.0, 'diesmal': 1.0, 'doppelt': 1.0, 'ein': 1.0, 'fügen': 1.0, 'hallo': 1.0, 'hinzu': 1.0, 'im': 1.0, 'ist': 1.0, 'manche': 1.0, 'noch': 1.0, 'sollen': 1.0, 'test': 1.0, 'text': 1.0, 'vorkommen': 1.0, 'weise': 1.0, 'weitere': 1.0, 'wir': 1.0, 'worte': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cd794d6-665e-413e-b712-53ebaf6f07a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model_path='../../models/embeddings/fastText.300.bin'\n",
    "model = fasttext.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1e8a417-8610-4c49-8e5a-32ef123c9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_16100\\3704550039.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(df.text.values):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6527edfb93654f70adc81f8c6912a8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "(3, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-5.57245499e-02, -4.61318800e-02, -4.87735027e-02,\n",
       "        -4.11862293e-02, -4.29207692e-02, -3.84600367e-03,\n",
       "        -4.02156552e-02,  2.08122786e-02, -7.82810152e-04,\n",
       "         6.89406972e-02, -1.40179898e-01,  2.43945094e-03,\n",
       "        -7.52108903e-02,  6.01536208e-02, -4.33068353e-02,\n",
       "        -1.58215186e-02,  2.21758275e-02,  8.83461988e-02,\n",
       "        -6.92135568e-02, -1.08139287e-01, -5.02664866e-02,\n",
       "         6.99156057e-02,  4.76662815e-03,  2.33393693e-02,\n",
       "        -3.28041923e-02,  2.76385183e-02, -1.14654179e-03,\n",
       "         2.89981328e-02, -5.60186007e-02,  2.00170563e-02,\n",
       "        -2.76690582e-03,  9.82630032e-03,  4.82663605e-02,\n",
       "         1.61939068e-02, -5.27699320e-02, -4.96995043e-02,\n",
       "         6.37732577e-02,  5.00381412e-02,  2.79426835e-02,\n",
       "         6.96885698e-02, -6.60432526e-03, -1.12128651e-02,\n",
       "         9.45695331e-02,  1.80075504e-03,  7.29615148e-03,\n",
       "         1.97931256e-02,  3.44543357e-03,  3.19165299e-02,\n",
       "         1.65598718e-02,  1.07263358e-01, -5.07178809e-03,\n",
       "        -4.14628428e-02,  8.58603441e-03, -6.54067392e-02,\n",
       "         1.80439511e-02,  7.46206944e-02, -5.87610416e-02,\n",
       "        -5.53435350e-02,  1.31628907e-03, -3.93161457e-02,\n",
       "        -6.18743302e-02,  4.35029378e-02,  2.32569985e-02,\n",
       "        -2.52406551e-02,  6.38444582e-02, -3.40485978e-02,\n",
       "         7.50897434e-02,  1.66462744e-02, -2.81798374e-02,\n",
       "         3.56889637e-02,  5.72037157e-02, -3.95586807e-02,\n",
       "         6.05391292e-02, -5.84272249e-02, -1.80364596e-02,\n",
       "        -1.11806320e-01, -1.23364436e-02, -7.45974369e-02,\n",
       "        -6.06973218e-02, -1.37405910e-02, -2.18570242e-02,\n",
       "        -1.75477128e-02, -1.62833009e-02,  1.58469206e-01,\n",
       "        -1.07184034e-02,  6.57286705e-02,  9.68303364e-02,\n",
       "         1.35329128e-02, -6.13442529e-03, -5.01480442e-03,\n",
       "         5.89399191e-04, -8.06757840e-02,  4.09879494e-02,\n",
       "        -1.20491813e-01,  3.67416879e-02,  2.71288322e-02,\n",
       "        -5.65765942e-02,  5.06808637e-02, -9.65141868e-02,\n",
       "         2.77312112e-03, -2.66832286e-02,  1.00244300e-02,\n",
       "         2.26233155e-02,  3.57671045e-02,  2.20266155e-02,\n",
       "        -1.68664100e-01,  4.29223275e-02, -7.02983495e-02,\n",
       "         3.68959471e-02, -4.34951251e-02,  6.00773348e-02,\n",
       "         1.18092615e-02, -2.58623899e-02, -1.30802959e-02,\n",
       "         1.69419441e-02,  1.31514207e-02, -2.14105034e-02,\n",
       "         3.23594720e-02,  4.42993855e-02,  4.95862765e-02,\n",
       "        -7.42287375e-03,  1.29629066e-02,  2.37416809e-02,\n",
       "        -1.52734499e-02,  1.94304809e-03,  9.37328339e-02,\n",
       "         1.79875828e-02, -3.40546127e-02,  1.25922803e-02,\n",
       "        -5.11206561e-02, -4.18089044e-02,  9.78147774e-02,\n",
       "        -3.91557054e-02,  2.43362146e-02,  3.99819170e-02,\n",
       "        -4.36274866e-02,  3.20965284e-02,  1.75856628e-01,\n",
       "         5.38615678e-02,  1.83155520e-02, -2.76141816e-02,\n",
       "        -2.40646577e-01,  3.28162624e-03,  3.56722054e-02,\n",
       "         6.25749421e-03, -1.84190719e-02,  2.28636228e-02,\n",
       "         5.29563241e-02, -3.82758977e-02, -9.26346611e-02,\n",
       "         4.36959108e-02,  2.84799315e-02, -1.73733465e-02,\n",
       "         8.06017090e-02,  3.52930423e-02,  4.52421380e-02,\n",
       "        -3.43965916e-02, -1.02193718e-01,  5.00915777e-02,\n",
       "        -4.40156416e-02, -6.24396084e-02,  3.11517539e-02,\n",
       "         4.81513878e-02, -1.69599236e-02,  1.05394366e-01,\n",
       "         1.04094761e-01,  3.80015327e-03, -2.88107860e-02,\n",
       "         5.26459721e-02,  6.87509761e-02, -3.88181978e-03,\n",
       "        -4.24463199e-02, -6.85641640e-02,  3.11763771e-02,\n",
       "         1.65337875e-02,  2.42134049e-02, -3.57280057e-02,\n",
       "         1.86141911e-02, -1.56998890e-01, -3.01731275e-02,\n",
       "         4.36381688e-02, -3.28444643e-02,  7.64618916e-02,\n",
       "        -1.12889902e-02, -2.83377673e-02, -6.49588834e-02,\n",
       "         3.84425071e-02, -1.42760240e-02, -4.24712554e-03,\n",
       "         2.56976001e-02,  6.10547564e-02,  4.70426020e-02,\n",
       "         8.13296468e-02, -1.75961598e-02,  3.00927605e-02,\n",
       "        -4.02735732e-03,  4.15377114e-02, -4.75075562e-04,\n",
       "         3.98892090e-02,  6.22150111e-02, -1.37113419e-01,\n",
       "         2.51306249e-02, -4.60361224e-02,  9.19158943e-03,\n",
       "         3.80604095e-02, -8.03126022e-02, -2.11453182e-02,\n",
       "        -2.78430525e-03, -4.16592476e-02,  9.79970396e-03,\n",
       "        -6.26025088e-02,  4.49187309e-02, -6.01906270e-02,\n",
       "        -7.71519043e-02, -2.60115424e-02,  6.09431691e-02,\n",
       "        -7.08197854e-02, -2.06308326e-02, -3.04215550e-02,\n",
       "         1.18896859e-02, -1.83920949e-02,  5.52744186e-02,\n",
       "         3.86188950e-02, -5.36582461e-02, -4.40420595e-02,\n",
       "        -3.95081942e-02, -1.15701486e-01,  1.45759946e-01,\n",
       "        -2.73000215e-02,  1.81144907e-02,  1.63743384e-02,\n",
       "         7.09217037e-02,  3.86912166e-03, -8.44436630e-02,\n",
       "        -1.50226782e-01, -3.15784616e-03, -9.07653337e-03,\n",
       "        -5.15133003e-02,  1.32226544e-01, -2.51525493e-02,\n",
       "         6.63854727e-02, -3.90456642e-02,  5.41192293e-02,\n",
       "        -1.41931154e-01,  4.63604851e-02,  6.77936855e-02,\n",
       "         5.42111350e-02, -1.03809118e-01, -5.78218616e-02,\n",
       "        -6.57864278e-02,  1.42293364e-01,  2.37253308e-03,\n",
       "        -1.38803368e-01,  1.09852800e-02,  6.59622001e-02,\n",
       "         3.39102927e-02, -1.10468600e-02,  3.09298057e-02,\n",
       "        -5.39266830e-03, -7.61033020e-02, -2.04769741e-02,\n",
       "        -7.99015537e-03,  1.06092216e-02,  8.60705390e-03,\n",
       "        -4.52043274e-02,  2.54805642e-02, -9.27368082e-02,\n",
       "         7.43337993e-02,  2.85557900e-02,  1.32613640e-01,\n",
       "         2.15254538e-03,  2.82995552e-02, -7.35079730e-02,\n",
       "        -1.51283280e-02, -8.52935357e-02,  6.88598333e-02,\n",
       "         3.66026469e-01,  3.39602787e-02, -6.59832419e-02,\n",
       "         1.10199986e-02,  1.60227632e-02,  7.04161860e-02,\n",
       "         2.90270506e-02, -4.46990319e-03,  3.16673138e-02,\n",
       "         8.49523605e-03, -9.02892025e-02,  1.02772703e-02,\n",
       "        -9.15780230e-02,  3.22406823e-02, -2.67729172e-02,\n",
       "         7.07764903e-02,  1.19878349e-02, -3.32384369e-02,\n",
       "        -4.06455384e-02,  1.10545643e-02, -4.16657249e-02,\n",
       "        -5.35040302e-02, -1.49799250e-01, -1.18188351e-01],\n",
       "       [-7.32391836e-02, -5.62355667e-03, -1.25364922e-02,\n",
       "        -4.37395014e-02, -8.85270946e-02, -7.14815799e-02,\n",
       "         1.75611414e-02, -6.60601251e-02,  9.13880654e-02,\n",
       "         5.74630415e-02, -7.20980568e-02, -7.99134374e-04,\n",
       "         1.00047036e-01,  9.10755610e-02, -6.12136824e-02,\n",
       "        -2.29367935e-02, -1.26511902e-02,  1.16505358e-01,\n",
       "        -2.81362194e-02, -9.58447605e-02, -1.75760733e-02,\n",
       "         8.96197557e-02,  4.00431510e-02,  6.28728457e-02,\n",
       "         1.61533332e-02, -5.08707389e-02, -3.40452422e-02,\n",
       "         1.35587119e-02, -7.85165087e-02, -3.16332867e-02,\n",
       "        -7.86147192e-02, -2.39962402e-02, -3.50825386e-02,\n",
       "        -1.54503789e-02, -1.20551437e-02, -1.08964257e-01,\n",
       "         1.08237088e-01,  1.13639399e-01,  5.20676058e-02,\n",
       "         7.34599046e-02, -1.33805830e-01, -1.01435890e-01,\n",
       "         2.78280620e-02, -1.32359006e-02, -8.31047492e-03,\n",
       "        -6.05982915e-03,  2.21162234e-02, -1.52010266e-02,\n",
       "         2.36047711e-02,  8.84559825e-02, -3.80729083e-02,\n",
       "        -2.40244437e-03, -4.69521480e-03, -9.27191786e-03,\n",
       "         4.57432773e-02,  7.55706429e-02, -5.78785129e-02,\n",
       "        -3.14291525e-02,  2.61883440e-02,  7.11430982e-03,\n",
       "         3.88002000e-02,  2.82559544e-03, -9.12276842e-03,\n",
       "         2.96287970e-02,  5.30722607e-02,  1.90304192e-02,\n",
       "         9.53937359e-02, -5.03318049e-02, -1.04380939e-02,\n",
       "        -1.31739713e-02, -1.11972522e-02, -5.63240238e-02,\n",
       "         1.26711659e-01,  9.16167144e-02, -2.76585631e-02,\n",
       "        -9.89077054e-02,  3.74300089e-02, -1.03644161e-02,\n",
       "        -9.33600813e-02, -3.07965782e-02,  5.71839623e-02,\n",
       "        -6.56121441e-02,  8.59350637e-02,  2.01973327e-01,\n",
       "         1.42140817e-02,  3.74972811e-02,  4.36506718e-02,\n",
       "         1.80516653e-02, -2.77164038e-02, -4.61122063e-02,\n",
       "        -1.59245392e-03,  3.27206776e-03,  1.19718518e-01,\n",
       "        -7.96856564e-02,  9.43423659e-02,  1.07592396e-01,\n",
       "        -7.33465981e-02,  1.11350603e-03, -8.42535980e-02,\n",
       "        -1.48279192e-02, -7.03072036e-03, -4.00108192e-02,\n",
       "         4.63990588e-02,  7.40042543e-02,  1.90710202e-02,\n",
       "        -8.83668959e-02,  8.85557160e-02, -3.70353404e-02,\n",
       "        -1.10991824e-01, -3.80214453e-02,  1.88393313e-02,\n",
       "         9.01959557e-03, -1.61950490e-02, -8.37236084e-02,\n",
       "         3.60100418e-02, -9.36780870e-03, -3.46886218e-02,\n",
       "        -7.70788770e-02,  2.59863064e-02, -1.69524373e-02,\n",
       "         1.16839148e-02,  6.94835875e-02, -7.79861538e-03,\n",
       "         1.50189679e-02, -2.86322646e-03,  9.29829888e-02,\n",
       "         6.29523620e-02,  3.17054028e-02, -5.53929210e-02,\n",
       "        -3.32373893e-02,  1.90917961e-02,  2.71136863e-02,\n",
       "        -2.62137352e-02,  1.09848581e-01,  1.79437408e-02,\n",
       "        -2.31128382e-02,  2.94656035e-02,  2.00624585e-01,\n",
       "        -7.11999368e-04,  2.15064362e-03,  4.37304424e-03,\n",
       "        -3.77500430e-02,  3.96934810e-02,  3.76604185e-02,\n",
       "         1.86128020e-02,  4.61973250e-03,  1.03346009e-01,\n",
       "         4.97666784e-02, -1.00627579e-01, -2.27631666e-02,\n",
       "         3.60007957e-02,  3.32982279e-02,  3.66651593e-03,\n",
       "        -3.28312479e-02,  4.65861335e-03, -3.48738618e-02,\n",
       "        -4.93984334e-02, -8.52387920e-02,  2.29485333e-04,\n",
       "        -5.75810820e-02, -8.23609121e-02,  4.85079680e-02,\n",
       "         1.05980188e-02, -3.18941795e-02,  7.48605859e-02,\n",
       "         5.08898273e-02, -6.50002901e-02, -5.61151858e-02,\n",
       "        -2.87045630e-02,  1.03399150e-01,  7.32568926e-02,\n",
       "        -4.79944628e-02, -5.18686054e-02,  2.74386415e-02,\n",
       "         4.52978536e-02, -9.64457728e-03, -4.40234710e-02,\n",
       "         4.81054876e-02,  1.52625795e-02, -2.90823746e-02,\n",
       "         3.71777024e-02, -4.87894043e-02,  3.48808449e-02,\n",
       "        -6.71075657e-03, -5.96404839e-02,  6.53352588e-02,\n",
       "         9.06010345e-03, -9.99708381e-03,  1.93346938e-02,\n",
       "         5.19271977e-02,  6.90876490e-02, -2.44745174e-02,\n",
       "         3.43919504e-02, -6.50423891e-02, -4.80386708e-03,\n",
       "         5.78096751e-02,  5.32764383e-02,  1.66990114e-02,\n",
       "         5.10089360e-02,  4.18153852e-02, -1.12786125e-01,\n",
       "         5.10201249e-02, -1.58102393e-01,  8.62894766e-02,\n",
       "        -2.83911331e-02, -5.04326615e-02, -1.91821158e-03,\n",
       "        -7.99760381e-02, -1.60999130e-02, -2.96550458e-02,\n",
       "        -1.73796751e-02,  3.17245573e-02, -9.58816893e-03,\n",
       "        -8.13159663e-02,  4.75967135e-02,  5.60391422e-02,\n",
       "         6.53715450e-02, -5.01463010e-02,  1.24078086e-02,\n",
       "         3.54650579e-02, -5.95050533e-02,  1.25666633e-02,\n",
       "         1.26479119e-02, -9.16481577e-02, -4.08536415e-02,\n",
       "        -6.89619966e-03, -6.57415874e-02,  1.46859422e-01,\n",
       "        -7.59682562e-02, -5.11158705e-02,  2.57587377e-02,\n",
       "         4.26403284e-02,  6.08551046e-02, -5.44218039e-02,\n",
       "        -7.77168795e-02,  1.65201686e-02, -3.75124998e-03,\n",
       "        -1.20168455e-01,  1.01647288e-01, -4.58169938e-03,\n",
       "         4.79204245e-02, -5.74823488e-02, -3.35046847e-03,\n",
       "        -6.35838509e-03, -2.67926631e-02,  1.30658918e-01,\n",
       "         2.95739537e-02, -1.11578196e-01, -3.86064127e-02,\n",
       "        -2.35492615e-02,  1.31622005e-01, -9.69985807e-02,\n",
       "        -9.62618850e-02,  2.67219031e-02,  4.11612820e-02,\n",
       "         2.37706695e-02,  4.53383578e-02, -3.20135318e-02,\n",
       "        -5.92870358e-02, -5.56258193e-02, -1.60934769e-02,\n",
       "         1.38191776e-02,  7.44197108e-02,  7.06759077e-02,\n",
       "        -5.55358315e-03,  6.11240678e-02, -1.11346145e-02,\n",
       "         1.13207702e-01,  8.36657826e-04,  2.67022457e-02,\n",
       "         4.35041124e-02, -2.98336111e-02, -1.29946612e-01,\n",
       "         1.20230466e-02,  2.89154414e-02, -1.61042809e-02,\n",
       "         2.48559564e-01,  1.11180648e-01, -1.00542614e-02,\n",
       "         1.80713225e-02, -7.91059481e-02, -2.32922155e-02,\n",
       "         2.40207333e-02, -7.76421800e-02,  6.80593876e-02,\n",
       "        -6.71401247e-03, -9.31806341e-02, -5.13525680e-03,\n",
       "        -1.07034350e-01,  6.39681667e-02,  4.35680803e-02,\n",
       "         1.18855163e-02,  6.61398005e-03, -3.64633861e-02,\n",
       "         5.95516255e-02, -6.30814787e-02,  2.36513950e-02,\n",
       "        -2.09929943e-02, -8.25114250e-02, -1.52381554e-01],\n",
       "       [-4.31026511e-02, -1.51562274e-02, -1.99503081e-02,\n",
       "        -6.74285553e-03, -3.30911724e-02,  3.80841230e-02,\n",
       "        -4.59573317e-02,  1.46919017e-02, -7.76911862e-03,\n",
       "         1.06894708e-01, -5.10873025e-02,  4.52786073e-05,\n",
       "        -9.38331872e-02,  1.01989591e-02, -4.65847490e-02,\n",
       "        -1.76236650e-02,  1.10783346e-01,  5.85605078e-02,\n",
       "        -1.22070024e-02, -1.53189144e-01, -3.12123058e-02,\n",
       "         3.68086580e-02,  2.09485553e-02,  3.40748358e-02,\n",
       "        -6.27645470e-02,  2.71666573e-02, -1.75891890e-02,\n",
       "         1.53116589e-02, -4.05921713e-03, -6.07114777e-02,\n",
       "         7.49392901e-02,  3.77465298e-02,  5.61912600e-02,\n",
       "        -6.59339547e-02, -2.46422822e-03, -1.75600553e-02,\n",
       "         5.08458690e-02,  2.21369214e-02,  1.33357254e-01,\n",
       "         2.62909435e-02, -1.11145405e-03,  1.78322446e-02,\n",
       "         7.73879010e-03,  9.72148813e-03, -1.71425954e-02,\n",
       "         8.40922317e-02,  1.42619977e-02,  5.58272898e-02,\n",
       "         3.98669989e-02,  7.99816493e-03, -8.13147370e-03,\n",
       "        -2.38234140e-02,  2.12899078e-02, -9.94628705e-03,\n",
       "        -4.08421382e-02,  3.49982667e-02, -1.32404240e-03,\n",
       "        -4.78777781e-02, -4.02939214e-02, -4.81450826e-02,\n",
       "        -8.05887122e-02,  3.13980477e-02, -1.70636825e-02,\n",
       "        -4.35905579e-02,  2.89823513e-02, -5.10634873e-02,\n",
       "         5.62449142e-02, -2.34262679e-02,  8.37251404e-04,\n",
       "         2.53564129e-02,  3.56776424e-02,  4.23810333e-02,\n",
       "         2.74431162e-02, -5.84177114e-02, -1.88194240e-02,\n",
       "        -4.24091302e-02, -2.27134473e-02, -1.08913140e-01,\n",
       "        -2.24596462e-02,  1.16213587e-02, -2.98120894e-02,\n",
       "        -1.03924796e-02, -3.86518132e-02,  7.04838470e-02,\n",
       "        -2.44043857e-02,  1.13077565e-01,  2.59698628e-02,\n",
       "        -2.11352438e-02,  1.81106031e-02, -2.64609294e-02,\n",
       "        -1.40106653e-01, -2.84890633e-02,  2.53926817e-02,\n",
       "        -4.40040376e-02,  4.74442150e-02,  7.57906325e-03,\n",
       "        -2.16834083e-02,  1.88640705e-02, -4.27143019e-02,\n",
       "         1.91060510e-02,  9.17868353e-03,  1.82953151e-02,\n",
       "         8.24422948e-03,  2.18961641e-02,  4.93369624e-02,\n",
       "        -1.01929533e-01,  1.39630230e-02, -7.99888521e-02,\n",
       "         2.94230241e-02, -3.54676710e-02, -1.76411681e-04,\n",
       "         6.41494494e-02, -1.71230829e-02, -1.05582803e-02,\n",
       "         3.07893977e-02,  3.75903964e-02, -2.13559236e-02,\n",
       "         3.21924550e-02,  4.77942608e-02, -9.58155245e-03,\n",
       "         1.47192629e-02,  1.10598413e-02, -4.30654921e-04,\n",
       "         5.04140556e-03,  3.46417874e-03,  6.07895071e-02,\n",
       "        -2.59382356e-02, -3.14408418e-02, -2.27814600e-02,\n",
       "        -4.85018983e-02, -6.41043998e-02,  8.85247745e-02,\n",
       "        -4.86086221e-02, -7.54967108e-03,  2.12049075e-02,\n",
       "        -6.78345840e-03,  8.36622138e-02,  9.55255859e-02,\n",
       "         5.12403028e-02, -2.73619370e-02, -3.99121519e-02,\n",
       "        -3.06785147e-01,  3.61987413e-02,  2.14015105e-02,\n",
       "        -2.82795308e-02, -1.38401235e-02,  6.22836314e-03,\n",
       "         3.52508396e-02, -1.53286068e-02, -2.27691315e-02,\n",
       "        -4.51317616e-04,  8.16573460e-02,  2.64686651e-03,\n",
       "        -7.04264790e-03, -1.32006736e-02,  1.26573048e-01,\n",
       "        -1.94089910e-02, -7.62707621e-02, -7.47316033e-03,\n",
       "        -5.18732783e-02, -2.03530548e-02,  8.28956859e-03,\n",
       "         2.99511064e-02, -9.50619243e-03,  1.71308368e-02,\n",
       "         5.20448513e-02, -4.44488302e-03,  2.11025462e-03,\n",
       "         9.22888260e-02,  2.18253286e-02, -2.25031508e-02,\n",
       "        -2.19551366e-02, -7.46076804e-02, -2.39899630e-02,\n",
       "         2.99195103e-02, -3.62356652e-02, -2.84864981e-02,\n",
       "         1.58050416e-02, -1.33180455e-01, -4.83235581e-02,\n",
       "         6.09393671e-02, -4.66059875e-02,  4.47815098e-03,\n",
       "         3.22815541e-02,  2.26046331e-02, -6.71414022e-02,\n",
       "         9.86476289e-02, -9.07366034e-03,  6.26246724e-02,\n",
       "         1.90400572e-02,  1.70301211e-02,  1.18582552e-02,\n",
       "         4.24512587e-02,  2.38164738e-03,  2.61812634e-02,\n",
       "         6.11700080e-02,  1.01096021e-01,  5.58479581e-02,\n",
       "         1.52316003e-02,  1.34071175e-02, -1.22841036e-01,\n",
       "        -1.16074843e-02, -3.96514270e-02, -1.23088155e-04,\n",
       "         3.05602261e-02, -1.54567851e-02,  2.12012973e-02,\n",
       "         9.84841958e-03, -5.19623335e-02,  1.54370658e-02,\n",
       "        -8.48904904e-03,  6.72568639e-02, -3.23537387e-02,\n",
       "        -3.92609648e-02, -9.76182753e-03,  1.89220630e-02,\n",
       "        -5.42542763e-02, -2.69586817e-02, -4.49575223e-03,\n",
       "         2.53444179e-03, -2.43328051e-02,  1.49466757e-02,\n",
       "         2.29507955e-02, -3.50836097e-02,  1.32279263e-02,\n",
       "        -1.00821499e-02, -4.06384699e-02,  1.13040526e-01,\n",
       "        -2.66040502e-02, -4.34956737e-03,  2.56269819e-02,\n",
       "         2.36309381e-02, -2.21307963e-02, -8.18105433e-03,\n",
       "        -1.34636905e-01, -1.23123522e-02, -1.18696261e-03,\n",
       "         8.56392393e-03,  1.47989681e-01, -1.85813807e-02,\n",
       "         2.33585626e-02, -4.97531347e-02, -4.65284644e-02,\n",
       "        -1.43736442e-01,  5.53716312e-02, -3.51331383e-04,\n",
       "         1.65879980e-02, -7.40839320e-02, -3.07442185e-02,\n",
       "         1.89057346e-02,  9.42412481e-02,  8.82586008e-03,\n",
       "         3.30455469e-02,  7.60762943e-03,  6.10320389e-02,\n",
       "         8.65171440e-03,  1.56002343e-03,  1.18539045e-02,\n",
       "        -1.92306377e-02, -8.14416975e-02, -6.92766028e-02,\n",
       "         8.94483037e-03,  2.75628395e-02, -1.89410152e-02,\n",
       "        -1.74419075e-02,  1.35602212e-02, -8.41667354e-02,\n",
       "         9.94030777e-03, -3.93386297e-03,  9.44138500e-02,\n",
       "        -1.15200911e-02, -3.86555791e-03, -1.05868364e-01,\n",
       "         6.28058352e-03, -7.18910757e-02,  4.97556448e-02,\n",
       "         3.08268806e-01,  3.66936242e-03, -6.31111275e-02,\n",
       "        -3.19010578e-02, -8.10392648e-03,  1.10917583e-01,\n",
       "        -4.75232041e-02,  6.80991397e-03,  5.41374657e-02,\n",
       "        -9.06556783e-03, -3.62432861e-02, -4.06878199e-02,\n",
       "        -3.30587002e-02,  3.62048569e-02, -2.98291957e-02,\n",
       "         3.33991259e-02,  1.39413024e-02, -5.98107502e-03,\n",
       "         1.71448149e-02,  2.47055210e-02, -7.41146687e-02,\n",
       "        -3.64193851e-02, -9.88241587e-02, -8.07417691e-02]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_embeddings(df, idf_dict, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a3ea034-a12b-4030-abcc-72c6f92b5ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "weights = [idf_dict.get(w, 1) for w in word_tokenize(\"dies ist ein test text\")]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb71e7a2-96eb-4edd-8429-7a36a2265de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "weights.append(idf_dict.get(\"dies\", 1))\n",
    "weights.append(idf_dict.get(\"ist\", 1))\n",
    "weights.append(idf_dict.get(\"ein\", 1))\n",
    "weights.append(idf_dict.get(\"test\", 1))\n",
    "weights.append(idf_dict.get(\"text\", 1))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fe94f-b5a7-4017-bb7e-759f006dc9b5",
   "metadata": {},
   "source": [
    "The fasttext model is quite big. lets try to quantize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86355411-0b69-4b19-8ace-57ca13bd7e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For now we only support quantization of supervised models",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mload_model(model_path)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Quantize the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save the quantized model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model(quantized_model_path)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterNLP\\lib\\site-packages\\fasttext\\FastText.py:358\u001b[0m, in \u001b[0;36m_FastText.quantize\u001b[1;34m(self, input, qout, cutoff, retrain, epoch, lr, thread, verbose, dsub, qnorm)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 358\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsub\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqnorm\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: For now we only support quantization of supervised models"
     ]
    }
   ],
   "source": [
    "quantized_model_path = 'fastText.300.quantized.ftz'\n",
    "\n",
    "# Load the model\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "# Quantize the model\n",
    "model.quantize(input=model_path, qnorm=True, retrain=True, cutoff=100000)\n",
    "\n",
    "# Save the quantized model\n",
    "model.save_model(quantized_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6557e90e-f05d-462e-9f2a-722d34def307",
   "metadata": {},
   "source": [
    "# New Sentiment XLMR test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfd57e84-543a-46f6-bf41-913c83627dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "\n",
    "def _preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def sentiment_analysis(df):\n",
    "    # Preprocess text (username and link placeholders)\n",
    "\n",
    "    MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "    # PT\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    model.save_pretrained(MODEL)\n",
    "    tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "    sentiments = []\n",
    "    for text in df.text.values:\n",
    "        text = _preprocess(text)\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        sentiments.append(scores)\n",
    "    \n",
    "    # [neg, neu, pos]\n",
    "    return np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "892ccc4f-2b06-4463-b639-ffb2f07f7cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12481989, 0.7195059 , 0.15567416],\n",
       "       [0.26906842, 0.57750887, 0.15342276],\n",
       "       [0.19121833, 0.74213284, 0.06664883]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b23ff-cb21-4c23-a985-c51467fbc7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b75bc1d-2ec9-4180-9eaf-bdd168b9cc2c",
   "metadata": {},
   "source": [
    "# Haystack documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a650c69-bff2-442b-80c3-8154e1fe53ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from haystack.nodes.base import BaseComponent\n",
    "from haystack.nodes import TransformersTranslator\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class CustomTranslator(BaseComponent):\n",
    "    outgoing_edges = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        # Store all init params in component's config so that we can easily save and load it via YAML\n",
    "        self.translator = TransformersTranslator(model_name_or_path=f'Helsinki-NLP/opus-mt-en-fr')\n",
    "        \n",
    "    def run(self, query, language='fr', **kwargs):\n",
    "        return self.translator.run(kwargs['documents'])\n",
    "    \n",
    "    def run_batch(self, queries: List[str], my_optional_param: Optional[int]) -> Dict[str, str]:\n",
    "        return self.translator.run(kwargs['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce39ba89-e3e4-4e6f-a803-26b3d7397886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from haystack.pipelines import Pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_node(component=CustomTranslator(), name='CustomTranslator', inputs=['Query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee2fbf38-72da-4beb-b2af-62c22e3225ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Exception while running node 'CustomTranslator': 'documents'\nEnable debug logging to see the data that was passed when the pipeline failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\haystack\\pipelines\\base.py:530\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[0;32m    529\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m` with input: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, node_id, node_input)\n\u001b[1;32m--> 530\u001b[0m     node_output, stream_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# The input might be a really large object with thousands of embeddings.\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;66;03m# If you really want to see it, raise the log level.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\haystack\\pipelines\\base.py:457\u001b[0m, in \u001b[0;36mPipeline._run_node\u001b[1;34m(self, node_id, node_input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_id: \u001b[38;5;28mstr\u001b[39m, node_input: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Dict, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnode_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\haystack\\nodes\\base.py:199\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03mThe Pipelines call this method when run() is executed. This method in turn executes the _dispatch_run_general()\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03mmethod with the correct run method.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_run_general\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\haystack\\nodes\\base.py:243\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run_general\u001b[1;34m(self, run_method, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m         run_inputs[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m--> 243\u001b[0m output, stream \u001b[38;5;241m=\u001b[39m \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Collect debug information\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m, in \u001b[0;36mCustomTranslator.run\u001b[1;34m(self, query, language, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslator\u001b[38;5;241m.\u001b[39mrun(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'documents'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the history of Quidditch?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\haystack\\pipelines\\base.py:535\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# The input might be a really large object with thousands of embeddings.\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;66;03m# If you really want to see it, raise the log level.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException while running node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with input \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, node_id, node_input)\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    536\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException while running node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnable debug logging to see the data that was passed when the pipeline failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    538\u001b[0m queue\u001b[38;5;241m.\u001b[39mpop(node_id)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: Exception while running node 'CustomTranslator': 'documents'\nEnable debug logging to see the data that was passed when the pipeline failed."
     ]
    }
   ],
   "source": [
    "query = \"What's the history of Quidditch?\"\n",
    "result = pipeline.run(query=query, params={\"language\": \"fr\"})\n",
    "result['documents'][0].text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1aa49ce",
   "metadata": {},
   "source": [
    "# Rasa Conversation Endpoint API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55238ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "conv='{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"events\":[{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"action\",\"timestamp\":1679141910.2501759529,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":12},\"name\":\"action_session_start\",\"policy\":null,\"confidence\":1.0,\"action_text\":null,\"hide_rule_turn\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"session_started\",\"timestamp\":1679141910.2502615452,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":13},\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"action\",\"timestamp\":1679141910.2502791882,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":14},\"name\":\"action_listen\",\"policy\":null,\"confidence\":null,\"action_text\":null,\"hide_rule_turn\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"user\",\"timestamp\":1679142150.4917826653,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":15},\"text\":\"hi\",\"parse_data\":{\"intent\":{\"name\":\"greet\",\"confidence\":0.9999992847},\"entities\":[],\"text\":\"hi\",\"message_id\":\"e578f2711ac64f27a0c5b354afe7a2b0\",\"metadata\":{},\"text_tokens\":[[0,2]],\"intent_ranking\":[{\"name\":\"greet\",\"confidence\":0.9999992847},{\"name\":\"bot_challenge\",\"confidence\":0.0000002408},{\"name\":\"deny\",\"confidence\":0.000000175},{\"name\":\"goodbye\",\"confidence\":0.0000001399},{\"name\":\"affirm\",\"confidence\":0.0000001215},{\"name\":\"mood_unhappy\",\"confidence\":0.000000038},{\"name\":\"mood_great\",\"confidence\":0.0000000365}],\"response_selector\":{\"all_retrieval_intents\":[],\"default\":{\"response\":{\"responses\":null,\"confidence\":0.0,\"intent_response_key\":null,\"utter_action\":\"utter_None\"},\"ranking\":[]}}},\"input_channel\":\"rasa\",\"message_id\":\"e578f2711ac64f27a0c5b354afe7a2b0\",\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"user_featurization\",\"timestamp\":1679142150.5018410683,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":16},\"use_text_for_featurization\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"action\",\"timestamp\":1679142150.5018565655,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":17},\"name\":\"utter_greet\",\"policy\":\"MemoizationPolicy\",\"confidence\":1.0,\"action_text\":null,\"hide_rule_turn\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"bot\",\"timestamp\":1679142150.5019516945,\"metadata\":{\"utter_action\":\"utter_greet\",\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":18},\"text\":\"Hey! How are you?\",\"data\":{\"elements\":null,\"quick_replies\":null,\"buttons\":null,\"attachment\":null,\"image\":null,\"custom\":null},\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"action\",\"timestamp\":1679142150.5083882809,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":19},\"name\":\"action_listen\",\"policy\":\"MemoizationPolicy\",\"confidence\":1.0,\"action_text\":null,\"hide_rule_turn\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"user\",\"timestamp\":1679142390.9550118446,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":20},\"text\":\"hallo dies ist ein test text lorem ipsum dolor sit amet\",\"parse_data\":{\"intent\":{\"name\":\"greet\",\"confidence\":0.4047514498},\"entities\":[],\"text\":\"hallo dies ist ein test text lorem ipsum dolor sit amet\",\"message_id\":\"d40ad4ef33494630bb8b51255e57c74b\",\"metadata\":{},\"text_tokens\":[[0,5],[6,10],[11,14],[15,18],[19,23],[24,28],[29,34],[35,40],[41,46],[47,50],[51,55]],\"intent_ranking\":[{\"name\":\"greet\",\"confidence\":0.4047514498},{\"name\":\"mood_great\",\"confidence\":0.204546839},{\"name\":\"bot_challenge\",\"confidence\":0.170268476},{\"name\":\"mood_unhappy\",\"confidence\":0.1399322599},{\"name\":\"deny\",\"confidence\":0.0519310795},{\"name\":\"affirm\",\"confidence\":0.0242456067},{\"name\":\"goodbye\",\"confidence\":0.0043243165}],\"response_selector\":{\"all_retrieval_intents\":[],\"default\":{\"response\":{\"responses\":null,\"confidence\":0.0,\"intent_response_key\":null,\"utter_action\":\"utter_None\"},\"ranking\":[]}}},\"input_channel\":\"rasa\",\"message_id\":\"d40ad4ef33494630bb8b51255e57c74b\",\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"user_featurization\",\"timestamp\":1679142390.9649317265,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":21},\"use_text_for_featurization\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"action\",\"timestamp\":1679142390.9649496078,\"metadata\":{\"query_intent\":{\"name\":\"greet\",\"score\":-1.3857530355,\"threshold\":-1.0310945511,\"severity\":0.3546584845},\"label_ranking\":[{\"name\":\"mood_great\",\"score\":1.9440969229,\"threshold\":-1.2006345987,\"severity\":-3.1447315216},{\"name\":\"mood_unhappy\",\"score\":1.5606993437,\"threshold\":-1.127918601,\"severity\":-2.6886179447},{\"name\":\"nlu_fallback\",\"score\":-1.3285272121,\"threshold\":null,\"severity\":null},{\"name\":\"goodbye\",\"score\":-1.3601157665,\"threshold\":null,\"severity\":null},{\"name\":\"restart\",\"score\":-1.3799036741,\"threshold\":null,\"severity\":null},{\"name\":\"greet\",\"score\":-1.3857530355,\"threshold\":-1.0310945511,\"severity\":0.3546584845},{\"name\":\"bot_challenge\",\"score\":-1.4138555527,\"threshold\":null,\"severity\":null},{\"name\":\"back\",\"score\":-1.4762108326,\"threshold\":null,\"severity\":null},{\"name\":\"deny\",\"score\":-1.4805110693,\"threshold\":-1.3753910065,\"severity\":0.1051200628},{\"name\":\"session_start\",\"score\":-1.6135823727,\"threshold\":null,\"severity\":null}],\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":22},\"name\":\"action_unlikely_intent\",\"policy\":\"UnexpecTEDIntentPolicy\",\"confidence\":1.0,\"action_text\":null,\"hide_rule_turn\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"action\",\"timestamp\":1679142390.9725646973,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":23},\"name\":\"utter_greet\",\"policy\":\"TEDPolicy\",\"confidence\":0.930875957,\"action_text\":null,\"hide_rule_turn\":false,\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"bot\",\"timestamp\":1679142390.9726576805,\"metadata\":{\"utter_action\":\"utter_greet\",\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":24},\"text\":\"Hey! How are you?\",\"data\":{\"elements\":null,\"quick_replies\":null,\"buttons\":null,\"attachment\":null,\"image\":null,\"custom\":null},\"is_flagged\":false},{\"sender_id\":\"2e14fc1bf1f64800b53a3244946e4905\",\"event\":\"action\",\"timestamp\":1679142390.9789199829,\"metadata\":{\"model_id\":\"d22244ae716b4846b330532a145fc3e5\",\"rasa_x_flagged\":false,\"rasa_x_id\":25},\"name\":\"action_listen\",\"policy\":\"TEDPolicy\",\"confidence\":0.9901733398,\"action_text\":null,\"hide_rule_turn\":false,\"is_flagged\":false}]}'\n",
    "conv=json.loads(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796b4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'events': [{'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'action', 'timestamp': 1679141910.250176, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 12}, 'name': 'action_session_start', 'policy': None, 'confidence': 1.0, 'action_text': None, 'hide_rule_turn': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'session_started', 'timestamp': 1679141910.2502615, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 13}, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'action', 'timestamp': 1679141910.2502792, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 14}, 'name': 'action_listen', 'policy': None, 'confidence': None, 'action_text': None, 'hide_rule_turn': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'user', 'timestamp': 1679142150.4917827, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 15}, 'text': 'hi', 'parse_data': {'intent': {'name': 'greet', 'confidence': 0.9999992847}, 'entities': [], 'text': 'hi', 'message_id': 'e578f2711ac64f27a0c5b354afe7a2b0', 'metadata': {}, 'text_tokens': [[0, 2]], 'intent_ranking': [{'name': 'greet', 'confidence': 0.9999992847}, {'name': 'bot_challenge', 'confidence': 2.408e-07}, {'name': 'deny', 'confidence': 1.75e-07}, {'name': 'goodbye', 'confidence': 1.399e-07}, {'name': 'affirm', 'confidence': 1.215e-07}, {'name': 'mood_unhappy', 'confidence': 3.8e-08}, {'name': 'mood_great', 'confidence': 3.65e-08}], 'response_selector': {'all_retrieval_intents': [], 'default': {'response': {'responses': None, 'confidence': 0.0, 'intent_response_key': None, 'utter_action': 'utter_None'}, 'ranking': []}}}, 'input_channel': 'rasa', 'message_id': 'e578f2711ac64f27a0c5b354afe7a2b0', 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'user_featurization', 'timestamp': 1679142150.501841, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 16}, 'use_text_for_featurization': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'action', 'timestamp': 1679142150.5018566, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 17}, 'name': 'utter_greet', 'policy': 'MemoizationPolicy', 'confidence': 1.0, 'action_text': None, 'hide_rule_turn': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'bot', 'timestamp': 1679142150.5019517, 'metadata': {'utter_action': 'utter_greet', 'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 18}, 'text': 'Hey! How are you?', 'data': {'elements': None, 'quick_replies': None, 'buttons': None, 'attachment': None, 'image': None, 'custom': None}, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'action', 'timestamp': 1679142150.5083883, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 19}, 'name': 'action_listen', 'policy': 'MemoizationPolicy', 'confidence': 1.0, 'action_text': None, 'hide_rule_turn': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'user', 'timestamp': 1679142390.9550118, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 20}, 'text': 'hallo dies ist ein test text lorem ipsum dolor sit amet', 'parse_data': {'intent': {'name': 'greet', 'confidence': 0.4047514498}, 'entities': [], 'text': 'hallo dies ist ein test text lorem ipsum dolor sit amet', 'message_id': 'd40ad4ef33494630bb8b51255e57c74b', 'metadata': {}, 'text_tokens': [[0, 5], [6, 10], [11, 14], [15, 18], [19, 23], [24, 28], [29, 34], [35, 40], [41, 46], [47, 50], [51, 55]], 'intent_ranking': [{'name': 'greet', 'confidence': 0.4047514498}, {'name': 'mood_great', 'confidence': 0.204546839}, {'name': 'bot_challenge', 'confidence': 0.170268476}, {'name': 'mood_unhappy', 'confidence': 0.1399322599}, {'name': 'deny', 'confidence': 0.0519310795}, {'name': 'affirm', 'confidence': 0.0242456067}, {'name': 'goodbye', 'confidence': 0.0043243165}], 'response_selector': {'all_retrieval_intents': [], 'default': {'response': {'responses': None, 'confidence': 0.0, 'intent_response_key': None, 'utter_action': 'utter_None'}, 'ranking': []}}}, 'input_channel': 'rasa', 'message_id': 'd40ad4ef33494630bb8b51255e57c74b', 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'user_featurization', 'timestamp': 1679142390.9649317, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 21}, 'use_text_for_featurization': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'action', 'timestamp': 1679142390.9649496, 'metadata': {'query_intent': {'name': 'greet', 'score': -1.3857530355, 'threshold': -1.0310945511, 'severity': 0.3546584845}, 'label_ranking': [{'name': 'mood_great', 'score': 1.9440969229, 'threshold': -1.2006345987, 'severity': -3.1447315216}, {'name': 'mood_unhappy', 'score': 1.5606993437, 'threshold': -1.127918601, 'severity': -2.6886179447}, {'name': 'nlu_fallback', 'score': -1.3285272121, 'threshold': None, 'severity': None}, {'name': 'goodbye', 'score': -1.3601157665, 'threshold': None, 'severity': None}, {'name': 'restart', 'score': -1.3799036741, 'threshold': None, 'severity': None}, {'name': 'greet', 'score': -1.3857530355, 'threshold': -1.0310945511, 'severity': 0.3546584845}, {'name': 'bot_challenge', 'score': -1.4138555527, 'threshold': None, 'severity': None}, {'name': 'back', 'score': -1.4762108326, 'threshold': None, 'severity': None}, {'name': 'deny', 'score': -1.4805110693, 'threshold': -1.3753910065, 'severity': 0.1051200628}, {'name': 'session_start', 'score': -1.6135823727, 'threshold': None, 'severity': None}], 'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 22}, 'name': 'action_unlikely_intent', 'policy': 'UnexpecTEDIntentPolicy', 'confidence': 1.0, 'action_text': None, 'hide_rule_turn': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'action', 'timestamp': 1679142390.9725647, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 23}, 'name': 'utter_greet', 'policy': 'TEDPolicy', 'confidence': 0.930875957, 'action_text': None, 'hide_rule_turn': False, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'bot', 'timestamp': 1679142390.9726577, 'metadata': {'utter_action': 'utter_greet', 'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 24}, 'text': 'Hey! How are you?', 'data': {'elements': None, 'quick_replies': None, 'buttons': None, 'attachment': None, 'image': None, 'custom': None}, 'is_flagged': False}, {'sender_id': '2e14fc1bf1f64800b53a3244946e4905', 'event': 'action', 'timestamp': 1679142390.97892, 'metadata': {'model_id': 'd22244ae716b4846b330532a145fc3e5', 'rasa_x_flagged': False, 'rasa_x_id': 25}, 'name': 'action_listen', 'policy': 'TEDPolicy', 'confidence': 0.9901733398, 'action_text': None, 'hide_rule_turn': False, 'is_flagged': False}]}\n"
     ]
    }
   ],
   "source": [
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7032923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['events'][0]['event']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
